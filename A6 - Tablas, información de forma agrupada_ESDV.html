<html>
    <head>
        <title>La&nbsp;ciencia e innovación&nbsp;tecnológica</title> 
    </head>
    <body>
        <body BGCOLOR="#78FF89"></body>

        <BODY BGCOLOR="#XXYYZZ" TEXT="#XX2768" LINK="#508990"
        VLINK="#2389ZZ" ALINK="#908423">

        <!–– Información sobre la inteligencia artificial ––>

        <h1><center>Inteligencia artificial : definición, historia, usos, peligros</center></h1>

        <h2>La inteligencia artificial es una tecnología tan amplia y revolucionaria que es difícil dar una definición precisa. Puede considerarse una rama del campo de la informática, cuyo objetivo es crear máquinas capaces de realizar tareas que tradicionalmente requerían inteligencia humana.</B></h2>

        <h2>Sin embargo, la IA es una ciencia interdisciplinaria con múltiples enfoques. Hoy en día, el Machine Learning (aprendizaje automático) y el Deep Learning (aprendizaje profundo) son dos técnicas utilizadas en empresas de todos los sectores.</h2>

        <h2>La inteligencia artificial va a cambiar el mundo, pero todavía sigue siendo un misterio para mucha gente. Descubre todo lo que tienes que saber sobre la IA en este dosier : definición, funcionamiento, historia, diferentes categorías, casos prácticos y aplicaciones.</I></h2>

        <IMG SRC="https://datascientest.com/es/files/2022/08/DALL%C2%B7E-2024-01-23-17.42.07-Une-illustration-originale-et-captivante-pour-un-article-sur-la-cybersecurite-en-format-16_9.-Limage-devrait-etre-dynamique-et-inventive-incluant-d-1-1024x585.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h1><center>¿Qué es la inteligencia artificial?</center></h1>

        <h2>En 1950, el matemático Alan Turing se hizo una pregunta: «¿Pueden pensar las máquinas?». De hecho, esta simple pregunta transformaría el mundo.</h2>

        <h2>El artículo de Alan Turing «Computing Machinery and Intelligence» y el consiguiente «Test de Turing» sentaron las bases de la inteligencia artificial, su visión y sus objetivos.</h2>

        <h2>De hecho, la inteligencia artificial pretende responder afirmativamente a la pregunta de Alan Turing. Su objetivo es replicar o simular la inteligencia humana en las máquinas.</h2>

        <h2>Se trata de un objetivo ambicioso, que también plantea muchos interrogantes y suscita el debate. Por ello, aún no existe una definición única de inteligencia artificial.</h2>

        <h2>La descripción de «máquinas inteligentes» no explica qué es realmente la inteligencia artificial ni qué hace que una máquina sea inteligente. En un intento de remediar este problema, Stuart Russell y Peter Norvig publicaron el libro «Artificial Intelligence: A Modern Approach».</h2>

        <h2>En ese libro, los dos expertos unifican sus trabajos sobre el tema de los agentes inteligentes en las máquinas. Según ellos, «la IA es el estudio de los agentes que reciben percepciones del entorno y realizan acciones».</h2>

        <h2>En su opinión, cuatro enfoques distintos han definido históricamente el campo de la inteligencia artificial: el pensamiento humano, el pensamiento racional, la acción humana y la acción racional.</h2>

        <h2>Los dos primeros enfoques se refieren al razonamiento y al procesamiento del pensamiento, mientras que los otros dos se refieren al comportamiento. En su libro, Norvig y Russell se centran principalmente en los agentes racionales capaces de actuar para conseguir el mejor resultado.</h2>

        <h2>Por su parte, Patrick Winston, profesor de inteligencia artificial del MIT, define la IA como «algoritmos activados por restricciones, expuestos por representaciones que soportan modelos que vinculan el pensamiento, la percepción y la acción».</h2>

        <h2>Otra definición moderna describe la IA como «máquinas que responden a simulaciones como los humanos, con capacidad de contemplación, juicio e intención». Estos sistemas son capaces de «tomar decisiones que normalmente requieren un nivel humano de conocimiento». Tienen tres cualidades que constituyen la esencia de la inteligencia artificial: intencionalidad, inteligencia y adaptabilidad.</h2>

        <h2>Estas diferentes definiciones pueden parecer abstractas y complejas. Sin embargo, ayudan a establecer la inteligencia artificial como una ciencia informática.</h2>

        <h2>En 2017, durante la Japan AI Experience, el CEO de DataRobot, Jeremy Achin, dio su propia definición moderna y con un toque de humor de la IA : «La inteligencia artificial es un sistema informático capaz de realizar tareas que normalmente requieren inteligencia humana… muchos de estos sistemas de IA se basan en el Machine Learning, otros en el Deep Learning y otros en cosas muy aburridas como las reglas«.</h2>

        <h1>Historia</h1>
        
        <h2>La historia de la inteligencia artificial comenzó en 1943 con la publicación del artículo «A Logical Calculus of Ideas Immanent in Nervous Activity» de Warren McCullough y Walter Pitts. En ese trabajo, los científicos presentaron el primer modelo matemático para la creación de una red neuronal.</h2>

        <h2>La historia de la inteligencia artificial comenzó en 1943 con la publicación del artículo «A Logical Calculus of Ideas Immanent in Nervous Activity» de Warren McCullough y Walter Pitts. En ese trabajo, los científicos presentaron el primer modelo matemático para la creación de una red neuronal.</h2>

        <h2>En 1952, Arthur Samuel creó un software capaz de aprender a jugar al ajedrez de forma autónoma. El término inteligencia artificial fue utilizado por primera vez en la conferencia «Dartmouth Summer Research Project on Artificial Intelligence» de John McCarthy en 1956.</h2>

        <h2>En ese acto, los investigadores presentaron los objetivos y la visión de la IA. Muchos consideran esta conferencia como el verdadero nacimiento de la inteligencia artificial, tal y como se conoce hoy en día.</h2>

        <h2>En 1959, Arthur Samuel acuñó el término Machine Learning mientras trabajaba en IBM. Por su parte, John McCarthy y Marvin Minsky fundaron el MIT Artificial Intelligence Project. En 1963, John McCarthy también creó el «AI Lab» en la Universidad de Stanford.</h2>

        <h2>En los siguientes años, se cernieron dudas sobre el campo de la IA. En 1966, el informe estadounidense ALPAC puso de manifiesto la falta de avances en la investigación de la traducción automática destinada a traducir simultáneamente la lengua rusa en el contexto de la Guerra Fría. Muchos proyectos financiados por el gobierno estadounidense fueron cancelados.</h2>

        <h2>Del mismo modo, en 1973, el gobierno británico publicó su informe «Lighthill» en el que destacaba las decepciones de la investigación en IA. Una vez más, los proyectos de investigación fueron reducidos por los recortes presupuestarios. Este periodo de duda duró hasta 1980, y ahora se denomina el «primer invierno de la IA«.</h2>

        <h2>Ese invierno terminó con la creación de R1 (XCON) por parte de Digital Equipment Corporations. Este sistema comercial experto está diseñado para configurar los pedidos de nuevos sistemas informáticos, y provocó un auténtico auge de las inversiones que se prolongó durante más de una década.</h2>

        <h2>Japón y Estados Unidos hicieron grandes inversiones en la investigación de la IA. Las empresas se gastaron más de mil millones de dólares al año en sistemas expertos y el sector no paraba de crecer.</h2>

        <h2>Desgraciadamente, el mercado de las máquinas “Lisp” se desplomó en 1987 al surgir alternativas más baratas. Este fue el «segundo invierno de la IA». Las empresas perdieron el interés por los sistemas expertos. Los gobiernos de Estados Unidos y Japón abandonaron sus proyectos de investigación y se gastaron miles de millones de dólares para nada.</h2>

        <h2>Diez años después, en 1997, la historia de la IA estuvo marcada por un acontecimiento importante. La IA Deep Blue de IBM triunfó sobre el campeón mundial de ajedrez Gary Kasparov. Por primera vez, el hombre fue derrotado por la máquina.</h2>

        <h2>Diez años después, los avances tecnológicos permitieron el resurgimiento de la inteligencia artificial. En 2008, Google hizo grandes avances en el reconocimiento de voz y lanzó esa función en sus aplicaciones para smartphones.</h2>

        <h2>En 2012, Andrew Ng alimentó una red neuronal con 10 millones de vídeos de YouTube como serie de datos de entrenamiento. Gracias al Deep Learning, esta red neuronal aprendió a reconocer un gato sin que se le enseñara lo que es un gato. Este fue el inicio de una nueva era para Deep Learning.</h2>

        <h2>En 2016 se produjo otra victoria de la IA sobre el ser humano, con el triunfo del sistema AlphaGo de Google DeepMind sobre Lee Sedol, el campeón de Go. La inteligencia artificial también conquistó el campo de los videojuegos, especialmente con DeepMind AlphaStar en Starcraft u OpenAI Five en Dota 2.</h2>

        <h2>Actualmente, empresas de todos los sectores utilizan el Deep Learning y el Machine Learning para infinidad de aplicaciones. La IA no deja de avanzar y sorprender con su rendimiento. El sueño de la inteligencia artificial general se acerca cada vez más a la realidad.</h2>

        <h1>Usos</h1>

        <h2>La inteligencia artificial tiene muchos propósitos, como el aprendizaje, el razonamiento y la percepción. Se utiliza en todos los sectores, hasta el punto en que las aplicaciones son infinitas e imposibles de enumerar con exhaustividad.</h2>

        <h2>En el ámbito de la salud, se utiliza para desarrollar tratamientos personalizados, descubrir nuevos fármacos o analizar imágenes médicas como radiografías y resonancias magnéticas. Los asistentes virtuales también pueden ayudar a los pacientes y recordarles que se tomen sus pastillas o que hagan ejercicio para mantenerse en forma.</h2>

        <h2>El sector del comercio minorista está utilizando la IA para ofrecer recomendaciones y publicidad personalizadas a los clientes. También puede utilizarse para optimizar la disposición de los productos o gestionar mejor el inventario.</h2>

        <h2>En las fábricas, la inteligencia artificial analiza los datos de los equipos IoT para predecir la carga y la demanda mediante Deep Learning. También puede anticiparse a posibles fallos de funcionamiento e intervenir en una fase temprana.</h2>

        <h2>Los bancos, por su parte, están utilizando la IA para prevenir y detectar el fraude. La tecnología también puede utilizarse para comprobar si un cliente podrá pagar el crédito que solicita y para automatizar las tareas de gestión de datos.</h2>

        <h2>Estos son solo algunos ejemplos de sectores que utilizan la inteligencia artificial. Como puede verse, esta revolucionaria tecnología está llamada a revolucionar todos los sectores de actividad en los próximos años.</h2>

        <h1>Peligros</h1>

        <h2>La inteligencia artificial ofrece muchas promesas para la humanidad, pero también podría representar una amenaza más peligrosa que la bomba nuclear.</h2>

        <h2>Con su capacidad de aprender y evolucionar de forma autónoma, la IA podría superar algún día la inteligencia humana. Entonces podría decidir volverse contra sus creadores.</h2>

        <h2>Este oscuro presagio puede parecer sacado directamente de una película de ciencia ficción, pero es una posibilidad muy real. Destacados expertos como Stephen Hawking, Elon Musk o Bill Gates ya han dado la voz de alarma sobre la inteligencia artificial.</h2>

        <h2>Según ellos, la IA representa un riesgo inminente e inevitable en los próximos años. Por eso piden a los gobiernos que regulen este campo para que se desarrolle de forma ética y segura. Más de un centenar expertos ha pedido también a Naciones Unidas que prohíba los «robots asesinos» y otras armas militares autónomas.</h2>

        <h2>Sin embargo, otros expertos creen que el futuro de la inteligencia artificial depende únicamente de cómo decidan utilizarla los humanos. Incluso una IA aparentemente inofensiva podría manipularse y utilizarse de forma malintencionada. Ya podemos verlo con el incremento de los «DeepFakes»: vídeos falsos creados mediante Deep Learning para mostrar a una persona en una situación comprometida.</h2>

        <h2>La inteligencia artificial seguirá desarrollándose a gran velocidad en los próximos años. La humanidad es quien debe decidir qué dirección tomará su desarrollo.</h2>

        <h1>IA especializada vs. IA general</h1>

        <h2>Hay dos categorías principales de inteligencia artificial. La inteligencia artificial de tipo «narrow» (estrecha), también conocida como «weak» (débil), solo puede funcionar en un contexto limitado. Suele centrarse en la realización de una única tarea, que es capaz de hacer perfectamente.</h2>

        <h2>Sin embargo, aunque esa máquina pueda parecer inteligente, es mucho más limitada que la inteligencia humana. No es más que una imitación de esta.</h2>

        <h2>Algunos ejemplos son el motor de búsqueda web de Google, el software de reconocimiento de imágenes, los asistentes virtuales como Siri de Apple o Alexa de Amazon, los vehículos autónomos o el software como Watson de IBM.</h2>

        <h2>En cambio, la segunda categoría es la inteligencia artificial «general». Esa IA es similar a las que se ven en las películas y libros de ciencia ficción.</h2>

        <h2>Es una máquina dotada de una inteligencia artificial general, comparable a la de un ser humano y capaz de resolver cualquier tipo de problema. Un algoritmo universal, capaz de aprender y actuar en cualquier entorno.</h2>

        <h2>Sin embargo, en realidad, este tipo de IA aún no existe. Ninguna tecnología está lo suficientemente avanzada hasta la fecha como para competir con el cerebro humano.</h2>

        <h2>Por ese motivo, la creación de la IA general sigue siendo, por el momento, el «Santo Grial» de los investigadores de IA. Es una búsqueda ambiciosa, pero llena de obstáculos. A pesar de los avances técnicos, sigue siendo muy difícil diseñar una máquina con plenas capacidades cognitivas.</h2>

        <h2>La inteligencia artificial es una tecnología tan amplia y revolucionaria que es difícil dar una definición precisa. Puede considerarse una rama del campo de la informática, cuyo objetivo es crear máquinas capaces de realizar tareas que tradicionalmente requerían inteligencia humana.</h2>

        <h2>Sin embargo, la IA es una ciencia interdisciplinaria con múltiples enfoques. Hoy en día, el Machine Learning (aprendizaje automático) y el Deep Learning (aprendizaje profundo) son dos técnicas utilizadas en empresas de todos los sectores.</h2>

        <h2>Pero, ¿Qué es Machine Learning y Deep Learning?</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/12/1-1024x576.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h1>Conceptos clave : IA, aprendizaje automático y aprendizaje profundo</h1>
        
        <h2>En los últimos años, un nuevo léxico relacionado con la aparición de la inteligencia artificial en nuestra sociedad ha inundado los artículos científicos, y a veces es difícil entender de qué se trata. Cuando hablamos de inteligencia artificial, muy a menudo nos referimos a tecnologías asociadas como el aprendizaje automático o el aprendizaje profundo. Dos términos muy utilizados con aplicaciones cada vez mayores, pero no siempre bien definidos.  Para empezar, veamos estas tres definiciones esenciales :</h2>

        <UL> <h2>
            <LI><B>Inteligencia artificial:</B> es un campo de investigación que reúne todas las técnicas y métodos que tienden a comprender y reproducir el funcionamiento de un cerebro humano.
            <LI> <B>Machine Learning:</B> se trata de un conjunto de técnicas que dan a las máquinas la capacidad de aprender automáticamente un conjunto de reglas a partir de los datos. A diferencia de la programación, que consiste en la ejecución de reglas predeterminadas.
            <LI> <B>Deep Learning:</B> es una técnica de aprendizaje automático basada en el modelo de red neuronal: se apilan decenas o incluso cientos de capas de neuronas para aportar mayor complejidad al establecimiento de reglas.
                </LI>
            </UL>

        <h1>Machine Learning : aprendizaje supervisado y no supervisado</h1>

        <h2>El Machine learning es un conjunto de técnicas que dan a las máquinas la capacidad de aprender, a diferencia de la programación, que consiste en la ejecución de reglas predeterminadas.</h2>

        <h2>Hay dos tipos principales de aprendizaje en el aprendizaje automático. Aprendizaje supervisado y no supervisado.</h2>

        <h2>En el aprendizaje supervisado, el algoritmo se guía por un conocimiento previo de cuáles deben ser los valores de salida del modelo. En consecuencia, el modelo ajusta sus parámetros para reducir la diferencia entre los resultados obtenidos y los esperados. Así, el margen de error se reduce a medida que el modelo se entrena para poder aplicarlo a nuevos casos.</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/09/DL-1.gif" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>En cambio, el aprendizaje no supervisado no utiliza datos etiquetados. Por lo tanto, es imposible que el algoritmo calcule una puntuación de éxito con certeza. Su objetivo es, por tanto, deducir los clusters presentes en nuestros datos. Tomemos el ejemplo de un conjunto de datos de flores, queremos agruparlas en clases. Aquí no conocemos la especie de la planta, pero queremos intentar agruparlas, por ejemplo, si las formas de las flores son similares, entonces están relacionadas con la misma planta correspondiente. Hay dos áreas principales de modelos en el aprendizaje no supervisado para encontrar agrupaciones :</h2>

        <UL> <h2>
            <LI><B>Métodos de partición: algoritmos k-means.
            <LI> <B>Métodos de agrupación jerárquica : clasificación jerárquica ascendente (HAC)
            </h2>
            </UL>

            <IMG SRC="https://datascientest.com/es/files/2020/09/DL-2.gif.pagespeed.ce_.sPGY6AGTSh.gif" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>¿Qué es el Deep Learning?</h2>

        <IMG SRC="https://datascientest.com/es/files/2022/04/deep_learning.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>El Deep learning es una de las principales tecnologías del aprendizaje automático. Con el Deep Learning, hablamos de algoritmos que son capaces de imitar las acciones del cerebro humano mediante redes neuronales artificiales.  Las redes se componen de docenas o incluso cientos de «capas» de neuronas, cada una de las cuales recibe e interpreta información de la capa anterior. </h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL3-1024x614.gif" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>Cada neurona artificial, representada en la imagen anterior por un círculo, puede verse como un modelo lineal. Al interconectar las neuronas en una capa, transformamos nuestra red neuronal en un modelo no lineal muy complejo.</h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL4.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>Para ilustrar el concepto, tomemos un problema de clasificación entre perro y gato a partir de imágenes. Durante el entrenamiento, el algoritmo ajustará los pesos de las neuronas para reducir la diferencia entre los resultados obtenidos y los esperados. El modelo podrá aprender a detectar triángulos en una imagen, ya que los gatos tienen las orejas mucho más triangulares que los perros.</h2>

        <h2>¿Para qué se utiliza el Deep Learning?</h2>

        <h2>Los modelos de aprendizaje profundo tienden a funcionar bien con grandes cantidades de datos, mientras que los modelos de aprendizaje automático más tradicionales dejan de mejorar después de un punto de saturación</h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL5.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>A lo largo de los años, con la aparición del big data y de componentes informáticos cada vez más potentes, los algoritmos de aprendizaje profundo que requieren mucha potencia y datos han superado a la mayoría de los demás métodos. Parecen estar preparadas para resolver muchos problemas: reconocer caras, ganar a jugadores de go o de póquer, permitir la conducción de coches autónomos o buscar células cancerígenas.</h2>

        <h2>La IA en el mundo profesional</h2>

        <h2>Casi todos los sectores se ven afectados por la IA. El aprendizaje automático y el aprendizaje profundo juegan un gran papel. </h2>

        <h2>Ya sea usted un profesional de la medicina o un abogado, es posible que un día un modelo altamente autónomo le asista o incluso le sustituya.</h2>

        <h2>En el sector de la salud , ya existen aplicaciones para diagnosticar automáticamente a un paciente.</h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL6-1024x654.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>La industria del automóvil también se ve sacudida por la llegada de la conducción asistida.</h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL7.gif" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>También es gracias al deep learning que el modelo Alpha Go de Google consiguió vencer a los mejores campeones de Go en 2016. El propio motor de búsqueda del gigante estadounidense se basa cada vez más en el aprendizaje profundo y no en reglas escritas.</h2>

        <h2>Hoy en día, el aprendizaje profundo es incluso capaz de «crear» cuadros por sí mismo. Esto se llama Transferencia de Estilo. Si está interesado en este tema, pronto estará disponible en nuestro blog un artículo enteramente dedicado a él.</h2>

        <IMG SRC="https://datascientest.com/wp-content/uploads/2020/06/DL8.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>A continuación, le presentaremos las redes neuronales con un nuevo enfoque, ¡esperamos que le guste!</h2>

        <h1><B><center>El aprendizaje profundo como solución en el comercio electrónico</center></B></h1>

        <h2>Es evidente que el sector del comercio electrónico genera grandes cantidades de datos. Las empresas, los comerciantes y los minoristas son conscientes de que las soluciones de Big Data para gestionar sus operaciones harán que su negocio sea más valioso. A pesar de todas estas soluciones innovadoras, el Big Data puede ser una bendición o una maldición, dependiendo de cómo se utilice y aplique.</h2>

        <h2>La revolución de la inteligencia artificial pretende facilitar la gestión de esta enorme cantidad de datos, utilizando tecnologías inteligentes como el aprendizaje profundo. Es esencial porque proporciona elementos para un mejor análisis de los datos.</h2>

        <h2>En un caso práctico, el análisis de la IA facilita que una tienda online ofrezca productos interesantes a sus clientes, destaque sus preferencias y les dé una atención personalizada. El aprendizaje profundo automatiza lo que se conoce como análisis predictivo. Con el análisis predictivo, los clientes pueden recibir sugerencias a la hora de realizar una compra.</h2>

        <h2>El aprendizaje profundo define un estilo cuando se trata de comercio electrónico. No se trata de crear sitios en línea que atraigan a grandes proporciones de compradores. El objetivo es enviar mensajes claros e individualizados a cada uno de ellos.</h2>

        <h2>El Big Data se somete a un análisis en profundidad a través del aprendizaje profundo, lo que conduce a un proceso de compra más fácil para los clientes. Los algoritmos de aprendizaje profundo ayudan a la empresa a obtener una mejor experiencia y a hacer un seguimiento de quienes han visitado su sitio.</h2>

        <h2>El aprendizaje profundo viene a facilitar la expansión del comercio electrónico. Las ventas online están siendo impulsadas por tendencias tecnológicas como los chatbots.</h2>

        <h2>En cierto modo, el aprendizaje profundo está redefiniendo el comercio en línea y todavía está en sus inicios. Por lo tanto, quienes lo adopten tendrán más ventajas.</h2>

        <h1><B><center>Deep Learning y redes neuronales : ¿biológicas o artificiales ? La misma batalla</center></B></h1>

        <h2>Antes de abordar el funcionamiento preciso de las redes neuronales, hemos pensado que sería interesante establecer un paralelismo con las neuronas biológicas (Que no cunda el pánico, a continuación habrá un artículo dedicado a las redes neuronales utilizadas en el Deep Learning).</h2>

        <B><h1>La neurona biológica : estructura y función</h1></B>

        <h2>El sistema nervioso está compuesto por miles de millones de células : es una red de neuronas biológicas. En efecto, las neuronas no son independientes unas de otras, sino que establecen vínculos entre ellas y forman redes más o menos complejas.</h2>

        <h2>La neurona biológica se compone de tres partes principales :</h2>

        <UL> <h2>
            <LI><B>El cuerpo celular compuesto por el centro de control que procesa la información recibida por las dendritas.
            <LI><B> Las dendritas son los cables principales por los que pasa la información del exterior.
            <LI> El axón es el cable conductor que lleva la señal de salida del cuerpo celular a otras neuronas.
            </h2>
            </UL>

        <IMG SRC="https://www.researchgate.net/profile/Clement-Hebert/publication/280792237/figure/fig1/AS:669573049245704@1536650063478/Schema-dun-neurone.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>En cuanto a las sinapsis, actúan como enlaces y pesos entre las neuronas y, por tanto, permiten que éstas se comuniquen entre sí.</h2>

        <IMG SRC="https://studdy.in/wp-content/uploads/2019/03/synapse.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h1><B>¿Cuál es el vínculo entre las neuronas biológicas y las artificiales?</B></h1>

        <h2>En Resumen :</h2>

        <h2>Las neuronas biológicas tienen un centro de control (llamado célula somática) que resume la información recogida por las dendritas. El centro de control devuelve entonces un potencial de acción según las siguientes reglas :</h2>

        <UL> <h2>
            <LI><B>Si la suma de entrada no supera el umbral de excitación : no hay mensaje nervioso a través del axón.
            <LI><B> Si la suma de entrada supera el umbral de excitación : se envía un mensaje nervioso a través del axón (esa es la idea, pero en realidad es un poco más complicado).
            </h2>
            </UL>

        <h2>Hagamos una sencilla comparación de los principales pasos del algoritmo del perceptrón con los bloques de construcción de las neuronas biológicas. Esta elección del algoritmo se justifica porque es lo más parecido al funcionamiento de las neuronas biológicas :</h2>

        <UL> <h2>
            <LI><B> Sinapsis/dendritas : ponderación de cada elemento de entrada
            <LI><B> Cuerpos celulares : aplicación de una función de activación f a la suma de las entradas ponderadas.
            <LI> Axón : resultado de nuestro modelo.
            </h2>
            </UL>

        <IMG SRC="https://datascientest.com/es/files/2020/06/content_content_neuron.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>El vocabulario específico de este algoritmo es el siguiente :</h2>

        <UL> <h2>
            <LI><B> El vector w se llama vector de pesos (que se ajusta durante el entrenamiento).
            <LI><B> El vector x se llama vector de entrada.
            </h2>
            </UL>

        <h2>f se denomina función de activación.</h2>

        <h2>Para la mayoría de las funciones de activación, el perceptrón consiste en encontrar el hiperplano de separación (definido por w) entre nuestras dos clases :</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/06/Capture-d%E2%80%99e%CC%81cran-2020-06-12-a%CC%80-13.17.07.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>El algoritmo simple del Perceptrón ya no se utiliza en la práctica, ya que otros algoritmos, como la Support Vector Machine, son mucho más eficaces. Además, las neuronas biológicas no se utilizan individualmente, sino que suelen estar vinculadas a otras neuronas.</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/06/500px-Neurons_big1.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>El interés por el algoritmo del perceptrón proviene de una técnica demostrada en 1989 por George Cybenko que consiste en enlazar y apilar capas de perceptrón para proporcionar una mayor complejidad. Un algoritmo de este tipo se llama Perceptrón Multicapa, a menudo abreviado como MLP.</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/06/Capture-d%E2%80%99e%CC%81cran-2020-06-12-a%CC%80-13.18.36-1024x454.png" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>En la figura anterior, el modelo consiste en clasificar (en 10 clases) imágenes de figuras manuscritas. Los cuadrados verdes son las entradas de nuestro modelo, los perceptrones están representados por círculos grises y los enlaces están representados por las flechas.</h2>

        <h2>En general, la última capa de nuestro modelo se utiliza para dar forma al resultado deseado. Aquí, como tenemos un problema de clasificación, queremos predecir la probabilidad de cada clase (número 0, número 1…). Por eso la última capa tiene 10 neuronas, ya que hay 10 clases, y una función de activación «softmax» para devolver una probabilidad.</h2>

        <h2>Es mucho más libre para las otras capas de nuestro modelo, es especialmente importante que las funciones de activación de los perceptrones sean no lineales para hacer el modelo más complejo. En la práctica, las funciones de activación tanh o ReLU son las más utilizadas.</h2>

        <h2>Al igual que en LEGO, corresponde al científico de datos elegir la arquitectura de su modelo.</h2>

        <IMG SRC="https://datascientest.com/es/files/2020/06/pile21-14749-a6581-e3a3f.png" ALT="IA" ALIGN="center" WIDTH="400" HEIGHT="200">

        <h2>Hay algunas arquitecturas que rinden más que otras, pero no hay ninguna regla matemática real detrás de ellas. Es la experiencia la que prima sobre la elección de las estructuras del modelo.</h2>

        <h1>Aplicaciones y casos prácticos de la inteligencia artificial</h1>

        <h2>La inteligencia artificial tiene muchos propósitos, como el aprendizaje, el razonamiento y la percepción. Se utiliza en todos los sectores, hasta el punto en que las aplicaciones son infinitas e imposibles de enumerar con exhaustividad.</h2>

        <h2>En el ámbito de la salud, se utiliza para desarrollar tratamientos personalizados, descubrir nuevos fármacos o analizar imágenes médicas como radiografías y resonancias magnéticas. Los asistentes virtuales también pueden ayudar a los pacientes y recordarles que se tomen sus pastillas o que hagan ejercicio para mantenerse en forma.</h2>

        <h2>El sector del comercio minorista está utilizando la IA para ofrecer recomendaciones y publicidad personalizadas a los clientes. También puede utilizarse para optimizar la disposición de los productos o gestionar mejor el inventario.</h2>

        <h2>En las fábricas, la inteligencia artificial analiza los datos de los equipos IoT para predecir la carga y la demanda mediante Deep Learning. También puede anticiparse a posibles fallos de funcionamiento e intervenir en una fase temprana.</h2>

        <h2>Los bancos, por su parte, están utilizando la IA para prevenir y detectar el fraude. La tecnología también puede utilizarse para comprobar si un cliente podrá pagar el crédito que solicita y para automatizar las tareas de gestión de datos.</h2>

        <h2>Estos son solo algunos ejemplos de sectores que utilizan la inteligencia artificial. Como puede verse, esta revolucionaria tecnología está llamada a revolucionar todos los sectores de actividad en los próximos años.</h2>

        <h1>La historia de la inteligencia artificial</h1>

        <h2>La historia de la inteligencia artificial comenzó en 1943 con la publicación del artículo «A Logical Calculus of Ideas Immanent in Nervous Activity» de Warren McCullough y Walter Pitts. En ese trabajo, los científicos presentaron el primer modelo matemático para la creación de una red neuronal.</h2>

        <h2>El primer ordenador de red neuronal, Snarc, fue creado en 1950 por dos alumnos de Harvard: Marvin Minsky y Dean Edmonds. Ese mismo año, Alan Turing publicó el Test de Turing, que todavía se utiliza hoy para valorar las IA.</h2>

        <h2>En 1952, Arthur Samuel creó un software capaz de aprender a jugar al ajedrez de forma autónoma. El término inteligencia artificial fue utilizado por primera vez en la conferencia «Dartmouth Summer Research Project on Artificial Intelligence» de John McCarthy en 1956.</h2>

        <h2>En ese acto, los investigadores presentaron los objetivos y la visión de la IA. Muchos consideran esta conferencia como el verdadero nacimiento de la inteligencia artificial, tal y como se conoce hoy en día.</h2>

        <h2>En 1959, Arthur Samuel acuñó el término Machine Learning mientras trabajaba en IBM. Por su parte, John McCarthy y Marvin Minsky fundaron el MIT Artificial Intelligence Project. En 1963, John McCarthy también creó el «AI Lab» en la Universidad de Stanford.</h2>

        <h2>En los siguientes años, se cernieron dudas sobre el campo de la IA. En 1966, el informe estadounidense ALPAC puso de manifiesto la falta de avances en la investigación de la traducción automática destinada a traducir simultáneamente la lengua rusa en el contexto de la Guerra Fría. Muchos proyectos financiados por el gobierno estadounidense fueron cancelados.</h2>

        <h2>Del mismo modo, en 1973, el gobierno británico publicó su informe «Lighthill» en el que destacaba las decepciones de la investigación en IA. Una vez más, los proyectos de investigación fueron reducidos por los recortes presupuestarios. Este periodo de duda duró hasta 1980, y ahora se denomina el «primer invierno de la IA«.</h2>

        <h2>Ese invierno terminó con la creación de R1 (XCON) por parte de Digital Equipment Corporations. Este sistema comercial experto está diseñado para configurar los pedidos de nuevos sistemas informáticos, y provocó un auténtico auge de las inversiones que se prolongó durante más de una década.</h2>

        <h2>Japón y Estados Unidos hicieron grandes inversiones en la investigación de la IA. Las empresas se gastaron más de mil millones de dólares al año en sistemas expertos y el sector no paraba de crecer.</h2>

        <h2>Desgraciadamente, el mercado de las máquinas “Lisp” se desplomó en 1987 al surgir alternativas más baratas. Este fue el «segundo invierno de la IA». Las empresas perdieron el interés por los sistemas expertos. Los gobiernos de Estados Unidos y Japón abandonaron sus proyectos de investigación y se gastaron miles de millones de dólares para nada.</h2>

        <h2>Diez años después, en 1997, la historia de la IA estuvo marcada por un acontecimiento importante. La IA Deep Blue de IBM triunfó sobre el campeón mundial de ajedrez Gary Kasparov. Por primera vez, el hombre fue derrotado por la máquina.</h2>

        <h2>Once años después, los avances tecnológicos permitieron el resurgimiento de la inteligencia artificial. En 2008, Google hizo grandes avances en el reconocimiento de voz y lanzó esa función en sus aplicaciones para smartphones.</h2>

        <h2>En 2012, Andrew Ng alimentó una red neuronal con 10 millones de vídeos de YouTube como serie de datos de entrenamiento. Gracias al Deep Learning, esta red neuronal aprendió a reconocer un gato sin que se le enseñara lo que es un gato. Este fue el inicio de una nueva era para Deep Learning.</h2>

        <h2>En 2016 se produjo otra victoria de la IA sobre el ser humano, con el triunfo del sistema AlphaGo de Google DeepMind sobre Lee Sedol, el campeón de Go. La inteligencia artificial también conquistó el campo de los videojuegos, especialmente con DeepMind AlphaStar en Starcraft u OpenAI Five en Dota 2.</h2>

        <h2>Actualmente, empresas de todos los sectores utilizan el Deep Learning y el Machine Learning para infinidad de aplicaciones. La IA no deja de avanzar y sorprender con su rendimiento. El sueño de la inteligencia artificial general se acerca cada vez más a la realidad.</h2>

        <h1>Los peligros de la inteligencia artificial</h1>

        <h2>La inteligencia artificial ofrece muchas promesas para la humanidad, pero también podría representar una amenaza más peligrosa que la bomba nuclear.</h2>

        <h2>Con su capacidad de aprender y evolucionar de forma autónoma, la IA podría superar algún día la inteligencia humana. Entonces podría decidir volverse contra sus creadores.</h2>

        <h2>Este oscuro presagio puede parecer sacado directamente de una película de ciencia ficción, pero es una posibilidad muy real. Destacados expertos como Stephen Hawking, Elon Musk o Bill Gates ya han dado la voz de alarma sobre la inteligencia artificial.</h2>

        <h2>Según ellos, la IA representa un riesgo inminente e inevitable en los próximos años. Por eso piden a los gobiernos que regulen este campo para que se desarrolle de forma ética y segura. Más de un centenar expertos ha pedido también a Naciones Unidas que prohíba los «robots asesinos» y otras armas militares autónomas.</h2>

        <h2>Sin embargo, otros expertos creen que el futuro de la inteligencia artificial depende únicamente de cómo decidan utilizarla los humanos. Incluso una IA aparentemente inofensiva podría manipularse y utilizarse de forma malintencionada. Ya podemos verlo con el incremento de los «DeepFakes»: vídeos falsos creados mediante Deep Learning para mostrar a una persona en una situación comprometida.</h2>

        <h2>La inteligencia artificial seguirá desarrollándose a gran velocidad en los próximos años. La humanidad es quien debe decidir qué dirección tomará su desarrollo.</h2>

       <h1> <center><I> Inteligencia&nbsp;artificial </I></center></h1>
       <h2> Los profetas de la inteligencia artificial (IA) y los medios de comunicaci&oacute;n están pronosticando el fin del auge de la IA generativa, con rumores de un inminente colapso catastr&oacute;fico de los modelos. Pero, &#191;hasta qu&eacute; punto son realistas estas predicciones? &#191;Y &#191;qu&eacute; es exactamente el colapso de modelos?</h2>
       <h2>Debatido en 2023, pero popularizado m&aacute;s recientemente, el &quot;colapso de modelos&quot; se refiere a un escenario hipot&eacute;tico en el que los futuros sistemas de IA se vuelven progresivamente menos eficientes debido al aumento de datos generados por IA en internet.</h2>
       <A NAME="MARCA"> </A> 

       <!–– Imagen ––>

       <IMG SRC="https://www.ionicgamers.com/wp-content/uploads/2019/07/istock-673815180-artificial-intelligence.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

       <p> <h1><center> <I>La&nbsp;necesidad&nbsp;de&nbsp;datos </I></center></h1></p>
       
       <p> <h2>Los sistemas modernos de IA se construyen utilizando aprendizaje autom&aacute;tico. Los programadores diseñan la estructura matem&aacute;tica subyacente, pero la verdadera &quot;inteligencia&quot; proviene de entrenar el sistema para imitar patrones en los datos. Pero no se trata de cualquier dato. Los sistemas de IA generativa actuales necesitan datos de alta calidad, y en grandes cantidades. Para obtener estos datos, grandes empresas tecnológicas como OpenAI, Google, Meta y Nvidia rastrean continuamente internet, recopilando terabytes de contenido para alimentar a las m&aacute;quinas. Sin embargo, desde la llegada de sistemas de IA generativa &uacute;tiles y ampliamente disponibles en 2022, cada vez m&aacute;s personas est&aacute;n subiendo y compartiendo contenido creado, en parte o en su totalidad, por IA. </h2></p>
        <p> <h2>En 2023, los investigadores empezaron a preguntarse si pod&iacute;an prescindir de los datos creados por humanos y depender &uacute;nicamente de los datos generados por IA para el entrenamiento.
        Hay grandes incentivos para que esto funcione. Adem&aacute;s de proliferar en internet, el contenido creado por IA es mucho m&aacute;s barato que los datos generados por humanos. Adem&aacute;s, recolectarlo en masa no presenta problemas &eacute;ticos ni legales.
        Sin embargo, los investigadores descubrieron que sin datos humanos de alta calidad, los sistemas de IA entrenados con datos generados por IA se vuelven cada vez menos eficientes a medida que cada modelo aprende del anterior. Es como una versión digital del problema de la endogamia.</h2></p>
        <p><h2>Este &quot;entrenamiento repetitivo&quot; parece llevar a una reducci&oacute;n en la calidad y diversidad del comportamiento del modelo. Calidad aqu&iacute; se refiere a una combinaci&oacute;n de ser &uacute;til, inofensivo y honesto. Diversidad se refiere a la variaci&oacute;n en las respuestas y a las perspectivas culturales y sociales representadas en las salidas de la IA. En resumen: al utilizar tanto los sistemas de IA, podr&iacute;amos estar contaminando la misma fuente de datos que necesitamos para que sean &uacute;tiles.</h2></p>
       
        <p><h1><center> <B>Evitar&nbsp;el&nbsp;colapso </B></center></h1></p>

        <!–– Imagen que lleva a otra página ––>

        <A HREF="https://forbes.es/_newspack_tech/498639/por-que-los-modelos-de-ia-estan-colapsando-y-que-significa-esto-para-el-futuro-de-la-tecnologia/#:~:text=Una%20de%20las%20principales%20soluciones,no%20est%C3%A1%20exenta%20de%20dificultades."><IMG SRC="https://www.mundodeportivo.com/urbantecno/hero/2024/09/asi-imagina-la-ia-su-propio-colapso.jpg?width=768&aspect_ratio=16:9&format=nowebp" BORDER="0"></A>

        <p><h2>&#191;No pueden las grandes tecnol&oacute;gicas simplemente filtrar el contenido generado por IA? No realmente. Las empresas tecnol&oacute;gicas ya invierten mucho tiempo y dinero en limpiar y filtrar los datos que recopilan, y seg&uacute;n un experto de la industria, a veces descartan hasta un 90% de los datos que recogen inicialmente para entrenar los modelos. </h2></p>
        <p><h2>Estos esfuerzos podr&iacute;an volverse a&uacute;n m&aacute;s exigentes a medida que aumente la necesidad de eliminar específicamente el contenido generado por IA. Pero, lo m&aacute;s importante, es que a largo plazo ser&aacute; cada vez m&aacute;s dif&iacute;cil distinguir el contenido generado por IA. Esto har&aacute; que filtrar y eliminar datos sint&eacute;ticos sea un esfuerzo de rendimiento decreciente (financieramente hablando). En última instancia, la investigación realizada hasta ahora muestra que simplemente no podemos prescindir por completo de los datos humanos. Despu&eacute;s de todo, es de donde proviene la &quot;I&quot; de la IA.</h2></p>
        <p><h2>Hay indicios de que los desarrolladores ya están teniendo que esforzarse m&aacute;s para obtener datos de alta calidad. Por ejemplo, la documentación que acompaña al lanzamiento de GPT-4 mencionaba a un n&uacute;mero sin precedentes de personal involucrado en las partes relacionadas con los datos del proyecto.</h2></p>
        <p><h2>También podríamos estar qued&aacute;ndonos sin nuevos datos humanos. Algunas estimaciones dicen que el conjunto de datos textuales generados por humanos podría agotarse sobre 2026. Es probable que por eso <A HREF="https://www.asilodigital.com/content/images/2023/02/twitter-1.png"> OpenAI </A> y otros est&eacute;n compitiendo para asegurar asociaciones exclusivas con gigantes de la industria como Shutterstock, Associated Press y NewsCorp. Estos poseen grandes colecciones de datos humanos propietarios que no est&aacute;n disponibles f&aacute;cilmente en internet.</h2></p>
        <h2>En los ultimos a&ntilde;os nos hemos enfrentado a problemas sobre la generaci&oacute;n de im&aacute;genes por una IA.</h2>

        <!–– Imagen que lleva a otra imagen ––>

        <A HREF="https://www.infobae.com/new-resizer/Su9zjw69LtSLkTUDq7_tQw_wJBo=/768x1152/filters:format(webp):quality(85)/cloudfront-us-east-1.images.arcpublishing.com/infobae/2R2U7JZSTVH2XDXNBH5TZRJGTY.jpeg"><IMG SRC="https://media.gq.com.mx/photos/641f07c8570db39374cd32a2/16:9/w_2560%2Cc_limit/Trump%2520(1).jpg" WIDTH="445" HEIGHT="270"></A>

        <!–– Lista sin orden alguno ––>

        <p><h2>Algunos temas de los que vamos a hablar tambi&eacute;n, son:</h2></p>
        <UL> <h2>
            <LI> <A HREF="file:///E:/Biotecnolog%C3%ADa.html"> Biotecnología </A>  <A HREF="https://www.primeraedicion.com.ar/nota/100914826/como-la-biotecnologia-ayuda-en-la-produccion-de-orquideas-en-la-tierra-colorada/"> Dato curioso sobre la biotecnología </A> 
            <LI> Nanotecnología  <!–– Enlace a pagina externa propia ––><A HREF="file:///E:/Nanotecnologia.html"> Contexto sobre la nanotecnologia </A> 
            <LI> <A HREF="file:///E:/Medio%20Ambiente.html"> Medio Ambiente </A>
            <LI> <A HREF="file:///E:/Comunicaciones.html"> Comunicaciones </A>
            </h2>
        </UL>

        <!–– Biotecnología ––>

        <h1><center>¿Qué ejemplos existen de biotecnología moderna en medicina?</center></h1>

        <h2>El futuro de la salud de las personas está, en gran parte, en la biotecnología médica. Como ejemplos, las terapias génicas y regenerativas, la medicina personalizada, los xenotrasplantes o la técnica de las tijeras genéticas.</h2>

        <IMG SRC="https://www.bbva.com/wp-content/uploads/2021/12/BBVA-biotecnologia_int2-1536x944.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h1><center>Medicina personalizada gracias a la biotecnología médica</center></h1>

        <h2>Conocer el perfil genético de una persona abre la puerta a la medicina personalizada, o de precisión, que a partir de esos datos genómicos y metabólicos emite diagnósticos y toma decisiones de prevención o tratamiento de una enfermedad. “Es la base para recomendar un medicamento u otro en función de sus efectos secundarios en ese organismo en concreto, o para elegir el tratamiento más adecuado en cada caso”.</h2>

        <h2>La Sociedad Española de Medicina Oncológica (SEOM) considera esta nueva aportación de la biotecnología médica como una “revolución en el tratamiento de los pacientes con cáncer”, al permitir decisiones terapéuticas de acuerdo con “las características genómicas y moleculares del tumor de cada paciente”.</h2>

        <h2>Otra puerta abierta para la biotecnología de la salud es la investigación en xenotrasplantes, es decir, el trasplante de órganos de animales —como cerdos y simios— en seres humanos.</h2>

        <h1><center>El corta-pega merece un Fronteras y un Nobel</center></h1>

        <h2>Puede que los nombres de Emmanuelle Charpentier y Jennifer A. Doudna tampoco le digan mucho al gran público. Pero estas dos científicas, la primera francesa y la segunda estadounidense, recibieron Premios Fundación BBVA Fronteras del Conocimiento en Biomedicina 2017 y el Premio Nobel de Química 2020 por el desarrollo de CRISPR-Cas9A, una técnica conocida como “tijeras genéticas” o “corta-pega genético”. Resumiendo al extremo el concepto, se trataría de ‘cortar’ el gen que causa una enfermedad y cambiarlo por otro que carezca de ese efecto. “Muchas enfermedades son provocadas por un producto génico que no funciona, que está mal regulado, que se produce en exceso o no se produce”.</h2>

        <h1><center>¿Qué tipos de biotecnología existen? Descubre sus colores</center></h1>

        <h2>La biotecnología, rama de la ciencia que utiliza sistemas biológicos y organismos vivos y sus derivados para crear o modificar productos con fines específicos, tiene tantos tipos como colores el arcoiris. Cada uno de ellos se vincula a distintas ramas. Descubre cuáles son.</h2>
        
        <IMG SRC="https://www.bbva.com/wp-content/uploads/2021/11/arcoiris_biotecnologi%CC%81a-sostenibilidad-BBVA.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>Hace un siglo, en 1919 un ingeniero agrónomo, Károly Ereky, definió por primera vez la biotecnología en el marco de la producción de una gran explotación agropecuaria. Aún quedarían nueve años para que Fleming descubriera el uso antibiótico de la penicilina en 1928. También, 24 para el descubrimiento del ADN en 1943. Incluso, 64 para la primera planta transgénica (modificada genéticamente) en 1983. Y 101 para que las investigaciones de las distintas biotecnologías liderasen la lucha contra la pandemia del coronavirus.</h2>

        <h2>Hoy la biotecnología moderna, aunque naciera como una disciplina asociada a la industria alimentaria, es multidimensional. Además, se estructura en distintas ramas (humana, animal, vegetal, industrial y ambiental). Es una disciplina presente en la salud y tratamiento de enfermedades, como la terapia génica, el diagnóstico molecular o las vacunas, en la mejora de cultivos y alimentos, en usos no alimentarios de esos cultivos (plásticos biodegradables, biocombustibles etc), en la industria (materiales inteligentes), o en el cuidado del medioambiente (procesos de biorremediación como el reciclaje y tratamiento de residuos y limpieza de contaminantes). En función de la aplicación de la biotecnología, han evolucionado como disciplinas independientes o áreas de I+D por colores:</h2>

        <h1>¿Qué estudia la biotecnología roja?</h1>
        
        <h2>Esta rama de la salud se ocupa, por ejemplo, de investigar sobre centenares de vacunas, como las que se diseñaron para hacer frente a la pandemia de COVID-19. Algunos otros ejemplos de su aplicación son el diseño de organismos para producir antibióticos, el desarrollo de nuevos fármacos, los diagnósticos moleculares, las terapias regenerativas y el desarrollo de la ingeniería genética para curar enfermedades a través de la investigación y terapia génica.</h2>

        <h1>¿Qué es la biotecnología verde?</h1>

        <h2>Es la rama que engloba las investigaciones relativas al sector agrícola y ganadero. Su foco es la mejora del rendimiento de cultivos y explotaciones ganaderas, en el ámbito de la biotecnología animal y vegetal. La mejora genética de especies animales y plantas, el desarrollo de plaguicidas cada vez más eficaces e inocuos con el medio ambiente, o la generación de nuevas especies con fines concretos son las aplicaciones más habituales de la biotecnología agroalimentaria, que marca la llamada tercera revolución verde tras la aparición de la agricultura en el Neolítico y el desarrollo de pesticidas, abonos y antibióticos para mejorar la salud animal en el siglo XX.</h2>

        <h1>¿Cómo se aplica la biotecnología en los alimentos?</h1>
        
        <h2>También llamada biotecnología amarilla o alimentaria. Derivada de la anterior, pero más enfocada en la producción de alimentos. Está asociada a cualquier alimento que se obtenga a partir de organismos vivos (como la cerveza, el vino, los destilados, el queso, el hummus o el pan), así como a los alimentos cuya producción se haya alterado incorporando compuestos mejorados genéticamente o enzimas para mejorar su proceso, esto es, para obtener más cantidad o alimentos de mejor calidad. Un ejemplo de innovación en este ámbito son los alimentos probióticos.</h2>

        <h1>¿Dónde se utiliza la biotecnología azul?</h1>

        <h2>Esta área de la investigación biotecnológica se centra en explorar la diversidad del medio marino, la acuicultura y los ecosistemas acuáticos. Una primera finalidad de la biotecnología azul está dirigida a la preservación de especies y ecosistemas marinos, pero no es la única: el desarrollo de medicamentos a partir de especies de estos ecosistemas, el suministro de alimentos de origen marino, la exploración de fuentes de bioenergía (por ejemplo producir biocombustibles a partir de algas), o la obtención de nuevos cosméticos son algunos de los frentes de esta I+D azul.</h2>

        <h1>¿Qué es la biotecnología blanca?</h1>

        <h2>Es la biotecnología enfocada a reducir o eliminar procesos contaminantes en la industria y sustituirlos por otros procesos más sostenibles. Uno de sus principales enfoques está en el tratamiento de los residuos industriales, aunque también apunta a la generación de energías limpias con base biológica o a la producción de plásticos biodegradables.</h2>

        <h1>¿Dónde se aplica la biotecnología dorada?</h1>

        <h2>Este tipo de biotecnología usa las tecnologías de la información y las comunicaciones para secuenciar los genomas de organismos vivos. Los análisis computacionales permiten simular procesos biológicos o generar bases de datos de ADN, modelar proteínas expresadas en cualquier organismo o, incluso diseñar genes ad hoc.</h2>

        <h1>¿Qué es la biotecnología purpura?</h1>

        <h2>Es la rama que profundiza en los aspectos legales y bioéticos que conlleva la aplicación de toda la investigación biotecnológica.</h2>

        <h2>En la siguiente tabla se muestra un resumen de la anterior información:</h2>

        <TABLE BORDER>

            <TABLE WIDTH="2000%">
            <TABLE WEIGHT="4000">

            <Table BORDER BGCOLOR="#9X5Z9"

            <TR>
            <TH>Tipo</TH> 
            <TH>¿Qué estudia?</TH> 
            </TR>

            <TR>
            <TD>Roja</TD>
            <TD>Investigar sobre vacunas, producción de antibióticos</TD>
            </TR>

            <TR>
            <TD>Verde</TD>
            <TD>Mejora del rendiento de cultivos y explotaciones ganaderas</TD>
            </TR>

            <TR>
            <TD>Azul</TD>
            <TD>Explorar la diversidad del medio marino, la agricultura y los ecosistemas acuáticos</TD>
            </TR>

            <TR>
            <TD>Blanca</TD>
            <TD>Reducir y eliminar procesos contaminantes en la industria y sustituirlos por otros procesos más sostenibles</TD>
            </TR>

            <TR>
            <TD>Dorada</TD>
            <TD>Secuenciar los genomas de organismos vivos, simular procesos biológicos o generar bases de datos de ADN</TD>
            </TR>

            <TR>
            <TD>Purpura</TD>
            <TD>Profundiza en los aspectos legales y bioéticos que conlleva la aplicación de la investigación biotecnologica</TD>
            </TR>

            </TABLE>

        <!–– Medio Ambiente ––>

        <h1><center>¿Qué es el medioambiente y por qué es clave para la vida?</center></h1>

        <h2>El medioambiente es el espacio en el que se desarrolla la vida de los distintos organismos favoreciendo su interacción. En él se encuentran tanto seres vivos como elementos sin vida y otros creados por la mano del hombre.</h2>

        <IMG SRC="https://www.bbva.com/wp-content/uploads/2023/08/elementos-que-conforman-el-medio-cambiente-2.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h2>Dentro de los primeros, agrupados bajo la denominación de factores bióticos, forman parte —además del ser humano y del resto de animales— toda la flora del planeta junto a los hongos y a pequeños organismos que cumplen funciones esenciales para el sostenimiento de la vida, y cuyo principal representante son las bacterias.</h2>

        <h2>Por otro lado, existen los elementos sin vida, conocidos como factores abióticos. Estos son esenciales para la subsistencia de los organismos vivos y conforman el espacio físico del ambiente, siendo los componentes básicos del ecosistema. Ejemplo de ellos son el agua, el aire y el suelo. En cuanto a los artificiales, destacan las tradiciones, la urbanización o la cultura. Estos se caracterizan por haber sido creados por el ser humano. La suma de todos conforma el medioambiente.</h2>

        <h1><center>La ciencia que estudia el medioambiente</center></h1>

        <h2>Todo lo relacionado con el medioambiente es estudiado por la ecología, una rama de la biología especializada en los seres vivos y en su interacción con el medio. Los especialistas de esta disciplina tienen en la forestación una cuestión fundamental. Hay que tener en cuenta que los árboles cumplen funciones vitales para gran parte de la fauna existente y para los seres humanos. Tanto es así que son los principales productores de oxígeno de los ecosistemas terrestres.</h2>

        <h2>Cada 5 de junio, el mundo conmemora el Día del Medioambiente. El objetivo es concienciar a la sociedad sobre la importancia de garantizar una protección duradera del planeta y sus recursos naturales. Las cifras hablan por sí solas: 1.200 toneladas de CO2 se vierten a la atmósfera cada segundo, 8.000 personas mueren al día en algún punto del planeta por causas relacionadas con la contaminación del aire, alrededor de 140.000 elefantes africanos desaparecieron en la última década como consecuencia de la falta de acceso a la alimentación o al agua. De ahí la importancia de contribuir a garantizar una sostenibilidad real a largo plazo de los ecosistemas.</h2>

        <IMG SRC="https://www.bbva.com/wp-content/uploads/2021/04/productores-basura-paises-desarrollados-bbva-sostenibilidad.jpg" ALT="IA" ALIGN="center" WIDTH="500" HEIGHT="300">

        <h1><center>El medioambiente, clave para la vida</center></h1>

        <h2>Cualquier organismo obtiene del medioambiente el sustento necesario para garantizar su supervivencia, no solo alimento, sino, también, refugio, aire o energía. Por eso, mantener su equilibrio resulta fundamental para asegurar la vida tal y como se conoce hoy en día. En el caso de los seres humanos, precisamos del consumo de gran cantidad de recursos naturales para comer, vestirnos o, incluso, para fabricar herramientas y otros productos que luego utilizamos en nuestras actividades diarias. Cuidar el ecosistema para hacer sostenible el uso de estos recursos y evitar su desaparición no es, por lo tanto, una filosofía simplemente bondadosa en relación con el planeta en el que vivimos, sino que nos va nuestra propia vida en ello.</h2>

        <h2>Por sí solos y sin ninguna intervención humana, la mayoría de los ecosistemas, comprendiendo dentro de estos la distinta flora y fauna que los conforman, serían autosuficientes, gracias al desarrollo de un equilibrio tal que garantizan su propia supervivencia a través de la biodiversidad. Sin embargo, la mano del hombre en el pasado ha sido letal para ellos, ya que el no cuidado de sus interacciones ha provocado la desaparición de especies o la reducción relevante en su número de especímenes vivos.</h2>

        <h2>Por todo ello, resulta fundamental la concienciación global de la sociedad para que realice un uso consciente y racional de los entornos con los que nos relacionamos. De este modo, además de garantizar la sostenibilidad, también se promueve el mantenimiento de los factores bióticos y abióticos para las generaciones futuras, de manera que, a largo plazo, se está trabajando colectivamente en el mantenimiento, en la conservación y en la mejora de los ecosistemas.</h2>

        <h2>Según el Banco Mundial, cuando el medioambiente y los recursos naturales se administran bien, pueden ser la base de un crecimiento sostenido e inclusivo, contribuyendo decisivamente a la reducción de la pobreza. Además, este organismo afirma que un tercio de las 100 ciudades más grandes del mundo se abastece de agua a partir de áreas protegidas, mientras que tres cuartas partes de los 115  principales cultivos alimentarios del mundo se basan en la polinización animal. En los países en desarrollo, los bosques, los lagos, los ríos y los océanos aportan una proporción considerable de los alimentos, combustibles e ingresos de los hogares, y constituyen una red de protección social muy valiosa en épocas de crisis, particularmente para los pobres que viven en zonas rurales.</h2>

        <H1>Calentamiento Global</H1>
        
        <TABLE BORDER>

            <TABLE WIDTH="2000%">
            <TABLE WEIGHT="3000">

            <Table BORDER BGCOLOR="#9X5Z9"

            <TR>
            <TH>Causas</TH> 
            <TH>Consecuencias</TH> 
            <TH>Soluciones</TH>
            </TR>

            <TR>
            <TD>Emisiones de gases</TD>
            <TD>Retienen el calor del sol</TD>
            <TD>Dejar de quemar combustibles fosiles</TD>
            </TR>

            <TR>
            <TD>Generacion de energía</TD>
            <TD>La mayor cantidad de emision de gases a nivel mundial</TD>
            <TD>Hacer uso de energias limpias</TD>
            </TR>

            <tr>
            <td>Productos manufacturados</td>
            <td>Quema de combustibles fosiles para producir energia</td>
            <TD>Usar enegia solar o eolica</TD>
            </tr>

            <tr>
            <td>Tala de bosques</td>
            <td>Los arboles liberan el CO2 que tenian almacenado</td>
            <TD>Hacer conciencia de la importancia que tienen</TD>
            </tr>

            <tr>
            <td>Transporte</td>
            <td>Emision de dioxido de carbono</td>
            <TD>Cambiar a un coche electrico</TD>
            </tr>

            <tr>
            <td>Produccion alimentaria</td>
            <td>El uso de fertilizantes emite metano</td>
            <TD>Usar fertilizantes que no emitan metano</TD>
            </tr>

            <tr>
            <td>Suministro electrico</td>
            <td>Uso de carbon, petroleo y gas natural</td>
            <TD>Cambiar a una produccion sostenible</TD>
            </tr>

            <tr>
            <td>Consumo excesivo</td>
            <td>El uso de bienes como ropa, electrónica y plásticos terminan en vertederos</td>
            <td>No comprar solo por comprar, mejor compra lo necesario y dale un buen uso</td>
            </tr>

            </TABLE>


        <!–– Enlace de correo ––>
        <h2><A HREF="mailto: edgar.diaz3112@alumnos.udg.mx"> Escribe algun comentario al editor de esta pagina </A> </h2>

        <!–– Enlace dentro de la misma pagina ––>
        <h2> <A HREF="file:///E:/A3-UC1-ESDV.html#MARCA"> Volver al segundo tema </A> </h2>

    </body>
</html>